{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['simulatedObs_sample.nc']\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 30)                3330      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 18)                558       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4818 (18.82 KB)\n",
      "Trainable params: 4818 (18.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "import glob \n",
    "\n",
    "fs=[\"simulatedObs_sample.nc\"]  # this is a sample of the simulated observations \n",
    "                               # results are likely to exhibit some differences relative to the paper\n",
    "                               # due to the small sample size\n",
    "xobs=[]\n",
    "iwc=[]\n",
    "print(fs)\n",
    "\n",
    "for f in fs[:]:\n",
    "    with Dataset(f) as fh:    # read data from netCDF file\n",
    "        tb_obs=fh[\"tb\"][:,:]\n",
    "        iwc_SSRG=fh[\"iwc_SSRG\"][:,:]\n",
    "        zKu=fh[\"zKu\"][:,:]\n",
    "        pnorm=fh[\"pnorm\"][:,:]\n",
    "\n",
    "    nt,nchan=tb_obs.shape   \n",
    "    lidarNoise=np.random.randn(nt,50)*0.1\n",
    "    pnorm=np.log10(1e-3*(pnorm)*10**lidarNoise+1e-9)  # add noise to lidar backscatter\n",
    "    pnorm[pnorm<-8.0]=-8.0                            # \"zero\" out values below the noise floor\n",
    "    zKu+=np.random.randn(nt,50)*0.5                   # add noise to radar reflectivity  \n",
    "    tb_obs+=np.random.randn(nt,nchan)*1               # add noise to radiometer brightness temperature\n",
    "    zKu[zKu<8]=0                                      # \"zero\" out values below the noise floor\n",
    "\n",
    "    lidarRadarRadiometerObs=np.concatenate((tb_obs,pnorm,zKu),axis=-1)  # concatenate all observations in one dimension\n",
    "    iwc.extend(iwc_SSRG)\n",
    "    xobs.extend(lidarRadarRadiometerObs)\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalerX=StandardScaler()    # define scaler for observations\n",
    "scalerY=StandardScaler()    # and for the target variable\n",
    "\n",
    "xobs=np.array(xobs)\n",
    "iwc=np.array(iwc)\n",
    "xobs_scaled=scalerX.fit_transform(xobs) # scale the observations\n",
    "iwc_scaled=scalerY.fit_transform(iwc)   # scale the target variable\n",
    "\n",
    "nc=18\n",
    "\n",
    "kmeans=MiniBatchKMeans(n_clusters=nc,random_state=0,batch_size=1024).fit(iwc_scaled)    # cluster the target variable into nc=18 clusters\n",
    "iwc_cluster=kmeans.labels_\n",
    "\n",
    "# split the data into training and testing\n",
    "# import train_test_split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,class_train,class_test,iwc_scaled_train,iwc_scaled_test=train_test_split(xobs_scaled,iwc_cluster,iwc_scaled,test_size=0.2,random_state=0)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# define the tensorflow classification model\n",
    "nC=18\n",
    "def get_model(nC,ninput=xobs_scaled.shape[-1]):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(30, activation='relu', input_shape=[ninput]),\n",
    "        layers.Dense(30, activation='relu'),\n",
    "        layers.Dense(nC, activation='softmax')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=losses.CategoricalCrossentropy())\n",
    "    return model\n",
    "\n",
    "\n",
    "model=get_model(nC)\n",
    "print(model.summary())\n",
    "# convert to one-hot encoding\n",
    "y_train_onehot=utils.to_categorical(class_train)\n",
    "y_test_onehot=utils.to_categorical(class_test)\n",
    "# standardize the data\n",
    "\n",
    "# train the model\n",
    "train=True\n",
    "if train==True:\n",
    "    history = model.fit(x_train[:,:], y_train_onehot,validation_data=(x_test[:,:], y_test_onehot),\n",
    "        batch_size=32,epochs=20, verbose=0)\n",
    "\n",
    "    model.save('lidarRadarRadiomClassifModel.demo.keras')\n",
    "else:\n",
    "    model=keras.models.load_model('lidarRadarRadiomClassifModel.demo.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the kalman gain for each cluster\n",
    "iwpC=[]\n",
    "kgainL=[]\n",
    "nx=x_train.shape[1]\n",
    "xobs_m=[]\n",
    "iwc_m=[]\n",
    "iwc_train=scalerY.inverse_transform(iwc_scaled_train)  # unscale the target variable\n",
    "iwc_test=scalerY.inverse_transform(iwc_scaled_test)    # unscale the target variable\n",
    "iwc_train[iwc_train<0]=0\n",
    "for i in range(nC):\n",
    "    a=np.nonzero(class_train==i)\n",
    "    xk=x_train[a[0],:]\n",
    "    yk=iwc_train[a[0],:]\n",
    "    covXY=np.cov(xk.T,yk.T)\n",
    "    covXX=covXY[:nx,:nx]+0.01*np.eye(nx)\n",
    "    covYX=covXY[nx:,:nx]\n",
    "    invCovXX=np.linalg.pinv(covXX)\n",
    "    kgain=np.dot(covYX,invCovXX)\n",
    "    kgainL.append(kgain)\n",
    "    xobs_m.append(np.mean(xk,axis=0))\n",
    "    iwc_m.append(np.mean(yk,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the kalman gain and the mean of the observations for each cluster in a pickle file\n",
    "\n",
    "import pickle\n",
    "with open('kgainL.demo.pkl','wb') as fh:\n",
    "    d={\"kgainL\":kgainL,\"xobs_m\":xobs_m,\"iwc_m\":iwc_m,\"scalerX\":scalerX,\"scalerY\":scalerY} # include the scalers for the observations and the target variable\n",
    "    pickle.dump(d,fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1032/1032 [==============================] - 0s 293us/step\n"
     ]
    }
   ],
   "source": [
    "#predict the iwc for the test data\n",
    "ninput=x_test.shape[1]\n",
    "class_onehot_=model.predict(x_test[:,:ninput])\n",
    "iwc_scaled_retL=[]\n",
    "for i,iwp1_ in enumerate(x_test[:,-1]):\n",
    "    iclass=np.argmax(class_onehot_[i,:])\n",
    "    iwc1=iwc_m[iclass]+np.dot(kgainL[iclass],x_test[i,:]-xobs_m[iclass])\n",
    "    iwc_scaled_retL.append(iwc1)\n",
    "\n",
    "iwc_ret=scalerY.inverse_transform(np.array(iwc_scaled_retL))\n",
    "iwc_ret=iwc_scaled_retL\n",
    "iwc_test=scalerY.inverse_transform(iwc_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
